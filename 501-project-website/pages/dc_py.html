<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.247">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>dc_py</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="dc_py_files/libs/clipboard/clipboard.min.js"></script>
<script src="dc_py_files/libs/quarto-html/quarto.js"></script>
<script src="dc_py_files/libs/quarto-html/popper.min.js"></script>
<script src="dc_py_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="dc_py_files/libs/quarto-html/anchor.min.js"></script>
<link href="dc_py_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="dc_py_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="dc_py_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="dc_py_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="dc_py_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#clustering-from-record-data" id="toc-clustering-from-record-data" class="nav-link active" data-scroll-target="#clustering-from-record-data">Clustering from Record Data</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#theory" id="toc-theory" class="nav-link" data-scroll-target="#theory">Theory</a>
  <ul class="collapse">
  <li><a href="#k-means-clustering" id="toc-k-means-clustering" class="nav-link" data-scroll-target="#k-means-clustering">K-Means Clustering</a></li>
  <li><a href="#dbscan-density-based-spatial-clustering-of-applications-with-noise" id="toc-dbscan-density-based-spatial-clustering-of-applications-with-noise" class="nav-link" data-scroll-target="#dbscan-density-based-spatial-clustering-of-applications-with-noise">DBSCAN (Density Based Spatial Clustering of Applications with Noise)</a></li>
  <li><a href="#hierarchical-agglomerative-vs-divisive-clustering" id="toc-hierarchical-agglomerative-vs-divisive-clustering" class="nav-link" data-scroll-target="#hierarchical-agglomerative-vs-divisive-clustering">Hierarchical (Agglomerative vs Divisive) Clustering</a></li>
  </ul></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a>
  <ul class="collapse">
  <li><a href="#data-selection" id="toc-data-selection" class="nav-link" data-scroll-target="#data-selection">Data Selection</a></li>
  <li><a href="#feature-selection-and-pre-processing" id="toc-feature-selection-and-pre-processing" class="nav-link" data-scroll-target="#feature-selection-and-pre-processing">Feature selection and Pre-processing</a></li>
  <li><a href="#separate-the-dataset-into-features-and-labels" id="toc-separate-the-dataset-into-features-and-labels" class="nav-link" data-scroll-target="#separate-the-dataset-into-features-and-labels">Separate the dataset into features and labels</a></li>
  </ul></li>
  <li><a href="#perform-k-means-clustering" id="toc-perform-k-means-clustering" class="nav-link" data-scroll-target="#perform-k-means-clustering">Perform K-means Clustering</a>
  <ul class="collapse">
  <li><a href="#hyper-parameter-tuning" id="toc-hyper-parameter-tuning" class="nav-link" data-scroll-target="#hyper-parameter-tuning">Hyper-parameter Tuning</a></li>
  <li><a href="#final-results-for-k-mean-clustering" id="toc-final-results-for-k-mean-clustering" class="nav-link" data-scroll-target="#final-results-for-k-mean-clustering">Final results for K-mean Clustering</a></li>
  </ul></li>
  <li><a href="#perform-dbscan-clustering" id="toc-perform-dbscan-clustering" class="nav-link" data-scroll-target="#perform-dbscan-clustering">Perform DBSCAN Clustering</a>
  <ul class="collapse">
  <li><a href="#hyper-parameter-tuning-1" id="toc-hyper-parameter-tuning-1" class="nav-link" data-scroll-target="#hyper-parameter-tuning-1">Hyper-parameter tuning</a></li>
  <li><a href="#final-results-for-dbscan" id="toc-final-results-for-dbscan" class="nav-link" data-scroll-target="#final-results-for-dbscan">Final Results for DBSCAN</a></li>
  </ul></li>
  <li><a href="#agglomerative-clustering-hierarchical-clustering" id="toc-agglomerative-clustering-hierarchical-clustering" class="nav-link" data-scroll-target="#agglomerative-clustering-hierarchical-clustering">Agglomerative Clustering (Hierarchical clustering)</a>
  <ul class="collapse">
  <li><a href="#plot-clusters" id="toc-plot-clusters" class="nav-link" data-scroll-target="#plot-clusters">Plot Clusters</a></li>
  <li><a href="#hyper-parameter-tuning-2" id="toc-hyper-parameter-tuning-2" class="nav-link" data-scroll-target="#hyper-parameter-tuning-2">Hyper-parameter Tuning</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">



<section id="clustering-from-record-data" class="level1">
<h1>Clustering from Record Data</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>The below page describes my data clustering process using record data. Data Clustering, or cluster analysis, is a type of unsupervised machine learning. It includes automatically grouping together datapoints that fit in together as groups naturally. In terms of the entire dataset, similar values are ones that are nearby each other and grouped together into clusters, and these clusters allow us to make inferences about our data. For clustering, we shall drop the target variable (Y) of recession (0 or 1), which leaves us with our feature data (X) to cluster with. We will also need to filter out our feature data, to accurately be able to perform clustering using record data.</p>
</section>
<section id="theory" class="level2">
<h2 class="anchored" data-anchor-id="theory">Theory</h2>
<section id="k-means-clustering" class="level3">
<h3 class="anchored" data-anchor-id="k-means-clustering">K-Means Clustering</h3>
<p>K-Means clustering is a type of partition-based or centroid-based clustering. Each cluster of our data points contain a centroid or a cluster center. In addition, it is also known as a non-parametric clustering algorither, which means that it doesn’t make strong assumptions about the form of the mapping function that maps input variables (X) onto output variables (Y). This algorithm minimizes the sum of squared distances between data points and their respective clusters centroid.</p>
<p>To better understand the steps of K-Means clustering, we can break down the algorithm into steps:</p>
<ul>
<li><ol type="1">
<li>Choose k random data points and assign them as cluster centers</li>
</ol></li>
<li><ol start="2" type="1">
<li>For every data point, see which centroid is nearest to it using a measurement method</li>
</ol></li>
<li><ol start="3" type="1">
<li>Assign the data point to the closest centroid</li>
</ol></li>
<li><ol start="4" type="1">
<li>Repeat the previous steps for all data points until the centroid stops changing</li>
</ol></li>
<li><ol start="5" type="1">
<li>The algorithm has now ‘converged’ when there are no more changes</li>
</ol></li>
</ul>
<p>Our model selection methods include the elbow method to choose the optimal value for ‘k’, or the number of clusters. This selection technique relies on two variables, intertia and distortion. Inertia is defined as the sum of squared distances of samples to their closest cluster center. Distortion, on the other hand, is calculated as the average of the squared distances from the cluster centers of their respective clusters, using Euclidean distance. After visualising the distortion and inertia values for various k values, we then select the value of k at the ‘elbow’ of the curve after which both inertia and distortion decrease in a linear value. An ideal model is one which has both low values of inertia and k, but both of these variables have an inverse relationship, causing a tradeoff.</p>
<p>Advantages of K-means:</p>
<ol type="1">
<li>Easy to understand and implement</li>
<li>Implementable to large datasets</li>
<li>Computationally efficient</li>
</ol>
<p>Disadvantages of K-means:</p>
<ol type="1">
<li>Manually choosing k value and depending on initial values</li>
<li>Sensitive to poor initialization of clusters</li>
<li>Centroids get dragged due to outliers in dataset</li>
</ol>
</section>
<section id="dbscan-density-based-spatial-clustering-of-applications-with-noise" class="level3">
<h3 class="anchored" data-anchor-id="dbscan-density-based-spatial-clustering-of-applications-with-noise">DBSCAN (Density Based Spatial Clustering of Applications with Noise)</h3>
<p>DBSCAN is a density-based algorithm which works on the assumption that clusters are desnse regions in space separated by regions of lower density. Densely grouped data points are grouped into a single cluster. Given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors). Outliers are marked as points that lie alone in low-density regions, whose nearest neighbors are too far away.</p>
<p>DBSCAN can be broken down into the following steps:</p>
<ol type="1">
<li>The algorithm arbitrarily picks a point in the dataset until all points have been visited</li>
<li>If there are at least minimum number of points (a threshold) clustered together for a region to be considered dense, within a radius of (a distance measure used to locate the points in the neighborhood of any point) to the point, then we consider all these points to be part of the same cluster. These minimum number of points, known as minPts, is one parameter for DBSCAN and is another parameter.</li>
<li>The clusters are then expanded by recursively repeating the neighborhood calculation for each neighboring point.</li>
</ol>
<p>The model selection method uses the silhouette score to select the optimal DBSCAN hyper-parameters. The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.</p>
<p>Advantages of DBSCAN:</p>
<ol type="1">
<li>It can handle noise very well</li>
<li>It can handle clusters of different shapes and sizes</li>
</ol>
<p>Disadvantages of DBSCAN:</p>
<ol type="1">
<li>DBSCAN tends to fail if the dataset contains multiple densities or varying densities</li>
<li>It is extremely sensitive to the hyperparameters, and a slight change in hyperparameters will drastically affect DBSCAN</li>
<li>The concept of density doesn’t apply well to highly-dimensional data</li>
</ol>
</section>
<section id="hierarchical-agglomerative-vs-divisive-clustering" class="level3">
<h3 class="anchored" data-anchor-id="hierarchical-agglomerative-vs-divisive-clustering">Hierarchical (Agglomerative vs Divisive) Clustering</h3>
<p>Hierarchical clustering technique is different from Partitional clustering, which divides the data into non-overlapping clusters such that each data point belongs to exactly one cluster. Hierarchical clustering can be thought of a set of nested clusters organized as a hierarchical tree, visualized through dendrograms. The agglomerative model is a type of Hierarchical Clustering, and is known as bottom-up clustering. It includes starting with the points as individual clusters, and at each step, moving up the hierarchy by merging the closest pair of clusters until only one cluster is left.</p>
<p>Hierarchical clustering’s process can be visualized with the help of a dendrograms, which are a type of tree diagram showing hierarchical relationships between different sets of data. The dendrogram can be used to decide when to stop merging the clusters or, in other words, finding the optimal number of clusters. We cut the dendrogram tree with a horizontal line at a height where the line can traverse the maximum distance up and down without intersecting the merging point.</p>
<p>Advantages of Hierarchical Clustering:</p>
<ol type="1">
<li>No need to decide how many clusters are required</li>
<li>Easy to use and implement</li>
</ol>
<p>Disadvantages of Hierarchical Clustering:</p>
<ol type="1">
<li>Can’t take a step back in this algorithm</li>
<li>High time complexity</li>
</ol>
</section>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<section id="data-selection" class="level3">
<h3 class="anchored" data-anchor-id="data-selection">Data Selection</h3>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>os.getcwd()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>'/Users/raunakadvani/anly-501-project-raunakadvani2410/501-project-website/pages'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import the necessary packages</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.cluster.hierarchy <span class="im">as</span> sch</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.cluster <span class="im">as</span> cluster</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>sns.set_theme(style<span class="op">=</span><span class="st">"whitegrid"</span>, palette<span class="op">=</span><span class="st">'Set2'</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"../../data/clean-data/Fredapi_clean.csv"</span>, index_col<span class="op">=</span>[<span class="dv">0</span>]) <span class="co"># read in data</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>df_cluster <span class="op">=</span> df.drop([<span class="st">'recession'</span>, <span class="st">'date'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>df_cluster.head() <span class="co"># visualize first 5 rows</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="31">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>gdp_value</th>
      <th>unemployment_value</th>
      <th>fed_funds_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>5872.701</td>
      <td>5.3</td>
      <td>8.25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5960.028</td>
      <td>5.3</td>
      <td>8.24</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6015.116</td>
      <td>5.7</td>
      <td>8.16</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6004.733</td>
      <td>6.1</td>
      <td>7.74</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6035.178</td>
      <td>6.6</td>
      <td>6.43</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df_cluster.shape <span class="co"># get the number of rows and columns</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>(134, 3)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_cluster.info()) <span class="co"># get column information</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 134 entries, 1 to 134
Data columns (total 3 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   gdp_value           134 non-null    float64
 1   unemployment_value  134 non-null    float64
 2   fed_funds_value     134 non-null    float64
dtypes: float64(3)
memory usage: 4.2 KB
None</code></pre>
</div>
</div>
</section>
<section id="feature-selection-and-pre-processing" class="level3">
<h3 class="anchored" data-anchor-id="feature-selection-and-pre-processing">Feature selection and Pre-processing</h3>
<p>As shown in the code above, our first step is to read in the cleaned dataset. Next, we must choose our target variable, which is the binary variable of recession. Then, we clean up our dataframe into a ‘cluster’ dataframe, which only contain our variables of federal funds rate (interest rate charged by the federal reserve) and the unemployment rate for the US</p>
</section>
<section id="separate-the-dataset-into-features-and-labels" class="level3">
<h3 class="anchored" data-anchor-id="separate-the-dataset-into-features-and-labels">Separate the dataset into features and labels</h3>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_cluster</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'recession'</span>]</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="perform-k-means-clustering" class="level2">
<h2 class="anchored" data-anchor-id="perform-k-means-clustering">Perform K-means Clustering</h2>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import relevent libraries for clustering</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statistics <span class="im">import</span> mode</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> cdist</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># for k means clustering we will use the elbow method to find the optimal number of clusters. </span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># we will use the inertia_ attribute to find the sum of squared distances of samples to their closest cluster center. </span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># we will use the range of 1 to 20 clusters and plot the inertia_ values for each cluster. </span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>distortions <span class="op">=</span> []</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>inertias <span class="op">=</span> []</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,k):</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    kmeansmodel <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, init<span class="op">=</span><span class="st">'k-means++'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    kmeansmodel.fit(X)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    distortions.append(<span class="bu">sum</span>(np.<span class="bu">min</span>(cdist(X, kmeansmodel.cluster_centers_, <span class="st">'euclidean'</span>), axis<span class="op">=</span><span class="dv">1</span>))<span class="op">/</span> X.shape[<span class="dv">0</span>])</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    inertias.append(kmeansmodel.inertia_)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    evaluation<span class="op">=</span>pd.DataFrame.from_records({<span class="st">"Cluster"</span>:np.arange(<span class="dv">1</span>,k<span class="op">+</span><span class="dv">1</span>), <span class="st">"Distortion"</span>:distortions, <span class="st">"Inertia"</span>:inertias})</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>evaluation</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="36">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Cluster</th>
      <th>Distortion</th>
      <th>Inertia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>4640.526068</td>
      <td>4.081628e+09</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>2464.638685</td>
      <td>1.195378e+09</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1650.946356</td>
      <td>5.086361e+08</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1325.920482</td>
      <td>3.251117e+08</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>964.815311</td>
      <td>1.743017e+08</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>771.498991</td>
      <td>1.158332e+08</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>663.664396</td>
      <td>8.742127e+07</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>574.559999</td>
      <td>6.493388e+07</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>502.475634</td>
      <td>5.125989e+07</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>476.442373</td>
      <td>4.290660e+07</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11</td>
      <td>429.365529</td>
      <td>3.494810e+07</td>
    </tr>
    <tr>
      <th>11</th>
      <td>12</td>
      <td>388.204518</td>
      <td>2.888627e+07</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13</td>
      <td>360.471354</td>
      <td>2.495954e+07</td>
    </tr>
    <tr>
      <th>13</th>
      <td>14</td>
      <td>339.637353</td>
      <td>2.197901e+07</td>
    </tr>
    <tr>
      <th>14</th>
      <td>15</td>
      <td>317.587103</td>
      <td>1.946993e+07</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot distortion and inertia for kmeans, you can either plot them seperately or use fig, ax = plt.subplots(1, 2) to plot them in the same figure. Suggest the optimal number of clusters based on the plot.</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>evaluation.plot.line(x<span class="op">=</span><span class="st">"Cluster"</span>, subplots<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>array([&lt;AxesSubplot:xlabel='Cluster'&gt;, &lt;AxesSubplot:xlabel='Cluster'&gt;],
      dtype=object)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-10-output-2.png" width="585" height="435"></p>
</div>
</div>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting clusters for best k = 3 (as per elbow method above)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>bestK <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, init<span class="op">=</span><span class="st">'k-means++'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>labels4 <span class="op">=</span> bestK.fit_predict(X)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'kmeans_labels'</span>] <span class="op">=</span> labels4</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"unemployment_value"</span>, y<span class="op">=</span><span class="st">"fed_funds_value"</span>, hue<span class="op">=</span><span class="st">"recession"</span>, data<span class="op">=</span>df, ax<span class="op">=</span>ax[<span class="dv">0</span>]).<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Unemployment Rate and Federal Funds Rate by Recession'</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"unemployment_value"</span>, y<span class="op">=</span><span class="st">"fed_funds_value"</span>, hue<span class="op">=</span><span class="st">"kmeans_labels"</span>, data<span class="op">=</span>df, ax<span class="op">=</span>ax[<span class="dv">1</span>]).<span class="bu">set</span>(title<span class="op">=</span><span class="st">'K-Means Clustering Plot'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>[Text(0.5, 1.0, 'K-Means Clustering Plot')]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-11-output-2.png" width="806" height="455"></p>
</div>
</div>
<p>According to the distortion and inertia values across the 2 graphs, we see that the initial K-means model yields k=3 clusters as the optimal number of clusters to use. The above scatterplots provide a binary representation of the two features, unemployment_value and fed_funds_value, of our feature data, to visualize the labels generated by the K-means model with k=3. Next, we’ll look at how the silhouette scores of the clusters affect our conclusions for this model.</p>
<section id="hyper-parameter-tuning" class="level3">
<h3 class="anchored" data-anchor-id="hyper-parameter-tuning">Hyper-parameter Tuning</h3>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># THIS WILL ITERATE OVER ONE HYPER-PARAMETER (GRID SEARCH) </span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># AND RETURN THE CLUSTER RESULT THAT OPTIMIZES THE SILHOUETTE SCORE</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.cluster</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> maximize_silhouette(X,algo<span class="op">=</span><span class="st">"birch"</span>,nmax<span class="op">=</span><span class="dv">20</span>,i_plot<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PARAM</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    i_print<span class="op">=</span><span class="va">False</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#FORCE CONTIGUOUS</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>np.ascontiguousarray(X) </span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># LOOP OVER HYPER-PARAM</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>[]<span class="op">;</span> sil_scores<span class="op">=</span>[]</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    sil_max<span class="op">=-</span><span class="dv">10</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> param <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>,nmax<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(algo<span class="op">==</span><span class="st">"kmeans"</span>):</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> sklearn.cluster.KMeans(n_clusters<span class="op">=</span>param).fit(X)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>model.predict(X)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>            sil_scores.append(sklearn.metrics.silhouette_score(X,labels))</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>            params.append(param)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span>:</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span> </span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(i_print): <span class="bu">print</span>(param,sil_scores[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(sil_scores[<span class="op">-</span><span class="dv">1</span>]<span class="op">&gt;</span>sil_max):</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>             opt_param<span class="op">=</span>param</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>             sil_max<span class="op">=</span>sil_scores[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>             opt_labels<span class="op">=</span>labels</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"OPTIMAL PARAMETER ="</span>,opt_param)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(i_plot):</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>        ax.plot(params, sil_scores, <span class="st">"-o"</span>)  </span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>        ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'Hyper-parameter'</span>, ylabel<span class="op">=</span><span class="st">'Silhouette Score'</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> opt_labels</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>k_means_opt_labels<span class="op">=</span>maximize_silhouette(X,algo<span class="op">=</span><span class="st">"kmeans"</span>,nmax<span class="op">=</span><span class="dv">15</span>, i_plot<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>OPTIMAL PARAMETER = 2</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-12-output-2.png" width="601" height="435"></p>
</div>
</div>
<p>When n_clusters = 2, the silhouette score is maximized on our entire feature data (X). This result is different from that of our elbow method, which yielded an optimal parameter of k=3 using the graphs which plot inertia and distortion along with different k values. The elbow method is used to find the ‘elbow’ point, where adding additional data samples does not change cluster membership much. The silhouette score allows us to determine whether there are large gaps between each sample and all other samples within the same cluster or across different clusters. The significant difference between the 2 methods is that while the elbow method only calculates euclidean distance, the silhouette method also takes into account variables such as variance, skewness, etc.</p>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_samples, silhouette_score</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.cm <span class="im">as</span> cm</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X[[<span class="st">"unemployment_value"</span>, <span class="st">"fed_funds_value"</span>]] </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>range_n_clusters <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>]</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_clusters <span class="kw">in</span> range_n_clusters:</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a subplot with 1 row and 2 columns</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    fig.set_size_inches(<span class="dv">18</span>, <span class="dv">7</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The 1st subplot is the silhouette plot</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The silhouette coefficient can range from -1, 1 but in this example all</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># lie within [-0.1, 1]</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlim([<span class="op">-</span><span class="fl">0.1</span>, <span class="dv">1</span>])</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The (n_clusters+1)*10 is for inserting blank space between silhouette</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plots of individual clusters, to demarcate them clearly.</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylim([<span class="dv">0</span>, <span class="bu">len</span>(X) <span class="op">+</span> (n_clusters <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> <span class="dv">10</span>])</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the clusterer with n_clusters value and a random generator</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># seed of 10 for reproducibility.</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>    clusterer <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>n_clusters, random_state<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    cluster_labels <span class="op">=</span> clusterer.fit_predict(X)</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The silhouette_score gives the average value for all the samples.</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This gives a perspective into the density and separation of the formed</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># clusters</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>    silhouette_avg <span class="op">=</span> silhouette_score(X, cluster_labels)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">"For n_clusters ="</span>,</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        n_clusters,</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">"The average silhouette_score is :"</span>,</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        silhouette_avg,</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the silhouette scores for each sample</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    sample_silhouette_values <span class="op">=</span> silhouette_samples(X, cluster_labels)</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>    y_lower <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_clusters):</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Aggregate the silhouette scores for samples belonging to</span></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># cluster i, and sort them</span></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>        ith_cluster_silhouette_values <span class="op">=</span> sample_silhouette_values[cluster_labels <span class="op">==</span> i]</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>        ith_cluster_silhouette_values.sort()</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>        size_cluster_i <span class="op">=</span> ith_cluster_silhouette_values.shape[<span class="dv">0</span>]</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>        y_upper <span class="op">=</span> y_lower <span class="op">+</span> size_cluster_i</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>        color <span class="op">=</span> cm.nipy_spectral(<span class="bu">float</span>(i) <span class="op">/</span> n_clusters)</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>        ax1.fill_betweenx(</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>            np.arange(y_lower, y_upper),</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>            <span class="dv">0</span>,</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>            ith_cluster_silhouette_values,</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>            facecolor<span class="op">=</span>color,</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>            edgecolor<span class="op">=</span>color,</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>            alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Label the silhouette plots with their cluster numbers at the middle</span></span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>        ax1.text(<span class="op">-</span><span class="fl">0.05</span>, y_lower <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> size_cluster_i, <span class="bu">str</span>(i))</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute the new y_lower for next plot</span></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>        y_lower <span class="op">=</span> y_upper <span class="op">+</span> <span class="dv">10</span>  <span class="co"># 10 for the 0 samples</span></span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="st">"The silhouette plot for the various clusters."</span>)</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(<span class="st">"The silhouette coefficient values"</span>)</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">"Cluster label"</span>)</span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The vertical line for average silhouette score of all the values</span></span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>    ax1.axvline(x<span class="op">=</span>silhouette_avg, color<span class="op">=</span><span class="st">"red"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>)</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>    ax1.set_yticks([])  <span class="co"># Clear the yaxis labels / ticks</span></span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticks([<span class="op">-</span><span class="fl">0.1</span>, <span class="dv">0</span>, <span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="dv">1</span>])</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2nd Plot showing the actual clusters formed</span></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>    colors <span class="op">=</span> cm.nipy_spectral(cluster_labels.astype(<span class="bu">float</span>) <span class="op">/</span> n_clusters)</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>    ax2.scatter(</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>        X[<span class="st">'unemployment_value'</span>], X[<span class="st">'fed_funds_value'</span>], marker<span class="op">=</span><span class="st">"."</span>, s<span class="op">=</span><span class="dv">30</span>, lw<span class="op">=</span><span class="dv">0</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, c<span class="op">=</span>colors, edgecolor<span class="op">=</span><span class="st">"k"</span></span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Labeling the clusters</span></span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>    centers <span class="op">=</span> clusterer.cluster_centers_</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw white circles at cluster centers</span></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>    ax2.scatter(</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>        centers[:, <span class="dv">0</span>],</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>        centers[:, <span class="dv">1</span>],</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>        marker<span class="op">=</span><span class="st">"o"</span>,</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>        c<span class="op">=</span><span class="st">"white"</span>,</span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>        alpha<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>        s<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>        edgecolor<span class="op">=</span><span class="st">"k"</span>,</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, c <span class="kw">in</span> <span class="bu">enumerate</span>(centers):</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>        ax2.scatter(c[<span class="dv">0</span>], c[<span class="dv">1</span>], marker<span class="op">=</span><span class="st">"$</span><span class="sc">%d</span><span class="st">$"</span> <span class="op">%</span> i, alpha<span class="op">=</span><span class="dv">1</span>, s<span class="op">=</span><span class="dv">50</span>, edgecolor<span class="op">=</span><span class="st">"k"</span>)</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="st">"Visualization of the Clustered Continuous Features"</span>)</span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(<span class="st">"unemployment_value"</span>)</span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">"fed_funds_value"</span>)</span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(</span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Silhouette analysis for KMeans clustering on Continuous Features with n_clusters = </span><span class="sc">%d</span><span class="st">"</span></span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a>        <span class="op">%</span> n_clusters,</span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>        fontsize<span class="op">=</span><span class="dv">14</span>,</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a>        fontweight<span class="op">=</span><span class="st">"bold"</span>,</span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>For n_clusters = 2 The average silhouette_score is : 0.49665636380652095</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For n_clusters = 3 The average silhouette_score is : 0.5179409466636461
For n_clusters = 4 The average silhouette_score is : 0.48485092517211287
For n_clusters = 5 The average silhouette_score is : 0.48939039355689806</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-13-output-3.png" width="1378" height="650"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-13-output-4.png" width="1378" height="650"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-13-output-5.png" width="1378" height="650"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-13-output-6.png" width="1378" height="650"></p>
</div>
</div>
<p>Silhouette plots seem to have an edge over the elbow method as using silhouette plots, one can evaluate clusters based on multiple criteria, including fluctuations in the size of the plot, non-uniform thickness, and the average Silhouette score (red dotted line). Thus, one can determine the optimal value for k using the above plots.</p>
<p>All n_clusters, from 2 to 5, have silhouette scores above that of the average silhouete score, which is the red dotted line. This means that we would need to look at the thickness fluctuations in the plots. When n_clusters = 2, the thickness of the silhouette plots suggests that the clusters are non-uniform.</p>
<p>For n_clusters = 3, the silhouette score is maximized, and the thickness of the silhouette plots is somewhat uniform. Hence, they clusters would be of similar sizes.</p>
</section>
<section id="final-results-for-k-mean-clustering" class="level3">
<h3 class="anchored" data-anchor-id="final-results-for-k-mean-clustering">Final results for K-mean Clustering</h3>
<p>When we cluster our entire feature data (X) we choose the optimal value of k to be 3, and this is based on the elbow method, the silhouette scores, and the silhouette plots. The code below is our final result for K-means clustering, visualizing 3 different clusters.</p>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting clusters for best k = 3 (as per silhouette method)</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>bestK <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, init<span class="op">=</span><span class="st">'k-means++'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>kmeans_labels_final <span class="op">=</span> bestK.fit_predict(X)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'kmeans_final_labels'</span>] <span class="op">=</span> kmeans_labels_final</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"unemployment_value"</span>, y<span class="op">=</span><span class="st">"fed_funds_value"</span>, hue<span class="op">=</span><span class="st">"recession"</span>, data<span class="op">=</span>df, ax<span class="op">=</span>ax[<span class="dv">0</span>]).<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Unemployment Rate and Federal Funds Rate by Recession'</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"unemployment_value"</span>, y<span class="op">=</span><span class="st">"fed_funds_value"</span>, hue<span class="op">=</span><span class="st">"kmeans_final_labels"</span>, data<span class="op">=</span>df, ax<span class="op">=</span>ax[<span class="dv">1</span>]).<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Final K-Means Clustering Plot'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>[Text(0.5, 1.0, 'Final K-Means Clustering Plot')]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-14-output-2.png" width="806" height="455"></p>
</div>
</div>
</section>
</section>
<section id="perform-dbscan-clustering" class="level2">
<h2 class="anchored" data-anchor-id="perform-dbscan-clustering">Perform DBSCAN Clustering</h2>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_cluster</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.5</span>, min_samples<span class="op">=</span><span class="dv">5</span>) </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>model.fit(X)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.fit_predict(X)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>labels_DB <span class="op">=</span> model.labels_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> []</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>nums <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>num_clusters <span class="op">=</span> []</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>num_samples <span class="op">=</span> []</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> nums:</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> samples:</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> DBSCAN(eps<span class="op">=</span>i, min_samples<span class="op">=</span>j).fit(X)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        labels_DB <span class="op">=</span> model.labels_ </span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>            score <span class="op">=</span> silhouette_score(X, labels_DB)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>            num_clusters.append(i)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>            scores.append(score)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>            num_samples.append(j)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">ValueError</span>:</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>sil_df <span class="op">=</span> pd.DataFrame({<span class="st">"number_of_clusters"</span>:num_clusters, <span class="st">"minimum_samples"</span>:num_samples, <span class="st">"silhouette_score"</span>:scores})</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a><span class="co"># sil_df.plot.scatter(x="minimum_samples", y="silhouette_score")</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>sil_df, x<span class="op">=</span><span class="st">"minimum_samples"</span>, y<span class="op">=</span><span class="st">"silhouette_score"</span>, hue<span class="op">=</span><span class="st">"number_of_clusters"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>&lt;AxesSubplot:xlabel='minimum_samples', ylabel='silhouette_score'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-16-output-2.png" width="601" height="435"></p>
</div>
</div>
<div class="cell" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>centers <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">1</span>], [<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>], [<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]]</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_cluster</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>labels_DB <span class="op">=</span> model.labels_</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>labels_true <span class="op">=</span> y</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> StandardScaler().fit_transform(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="17">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.3</span>, min_samples<span class="op">=</span><span class="dv">10</span>).fit(X)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>core_samples_mask <span class="op">=</span> np.zeros_like(db.labels_, dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>core_samples_mask[db.core_sample_indices_] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> db.labels_</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of clusters in labels, ignoring noise if present.</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>n_clusters_ <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(labels)) <span class="op">-</span> (<span class="dv">1</span> <span class="cf">if</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">in</span> labels <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>n_noise_ <span class="op">=</span> <span class="bu">list</span>(labels).count(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated number of clusters: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> n_clusters_)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated number of noise points: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> n_noise_)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Homogeneity: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.homogeneity_score(labels_true, labels))</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Completeness: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.completeness_score(labels_true, labels))</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"V-measure: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.v_measure_score(labels_true, labels))</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Adjusted Rand Index: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.adjusted_rand_score(labels_true, labels))</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Adjusted Mutual Information: </span><span class="sc">%0.3f</span><span class="st">"</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    <span class="op">%</span> metrics.adjusted_mutual_info_score(labels_true, labels)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Silhouette Coefficient: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.silhouette_score(X, labels))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated number of clusters: 3
Estimated number of noise points: 104
Homogeneity: 0.054
Completeness: 0.023
V-measure: 0.033
Adjusted Rand Index: -0.082
Adjusted Mutual Information: 0.009
Silhouette Coefficient: -0.109</code></pre>
</div>
</div>
<p>The above information corresponds to the performance of the DBSCAN model we chose initially, with default hyper-parameter values. The silhouette score is -0.109, which signifies that the data points are not well clustered to their own cluster, in comparison to other clusters. However, the model generates 3 clusters, which is the same result yielded by K-means clustering which was performed above.</p>
<p>Now, we will try to visualize the silhouette scores along with the number of clusters.</p>
<div class="cell" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>sil_df, x<span class="op">=</span><span class="st">"minimum_samples"</span>, y<span class="op">=</span><span class="st">"silhouette_score"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>&lt;AxesSubplot:xlabel='minimum_samples', ylabel='silhouette_score'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-19-output-2.png" width="601" height="435"></p>
</div>
</div>
<div class="cell" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>sns.lineplot(data<span class="op">=</span>sil_df, x<span class="op">=</span><span class="st">"number_of_clusters"</span>, y<span class="op">=</span><span class="st">"silhouette_score"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>&lt;AxesSubplot:xlabel='number_of_clusters', ylabel='silhouette_score'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-20-output-2.png" width="601" height="435"></p>
</div>
</div>
<section id="hyper-parameter-tuning-1" class="level3">
<h3 class="anchored" data-anchor-id="hyper-parameter-tuning-1">Hyper-parameter tuning</h3>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Defining the list of hyperparameters to try</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.metrics <span class="im">as</span> metrics</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Defining the list of hyperparameters to try</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>eps_list<span class="op">=</span>np.arange(start<span class="op">=</span><span class="fl">0.01</span>, stop<span class="op">=</span><span class="dv">4</span>, step<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>min_sample_list<span class="op">=</span>np.arange(start<span class="op">=</span><span class="dv">5</span>, stop<span class="op">=</span><span class="dv">10</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating empty data frame to store the silhouette scores for each trials</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>silhouette_scores_data<span class="op">=</span>pd.DataFrame()</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> eps_trial <span class="kw">in</span> eps_list:</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> min_sample_trial <span class="kw">in</span> min_sample_list:</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generating DBSAN clusters</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>        db <span class="op">=</span> DBSCAN(eps<span class="op">=</span>eps_trial, min_samples<span class="op">=</span>min_sample_trial)</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="bu">len</span>(np.unique(db.fit_predict(X)))<span class="op">&gt;=</span><span class="dv">2</span>):</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>            sil_score<span class="op">=</span>silhouette_score(X, db.fit_predict(X))</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>        trial_parameters<span class="op">=</span><span class="st">"eps:"</span> <span class="op">+</span> <span class="bu">str</span>(eps_trial.<span class="bu">round</span>(<span class="dv">1</span>)) <span class="op">+</span><span class="st">", min_sample:"</span> <span class="op">+</span> <span class="bu">str</span>(min_sample_trial)</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>        silhouette_scores_data<span class="op">=</span>silhouette_scores_data.append(pd.DataFrame(data<span class="op">=</span>[[sil_score,trial_parameters]], columns<span class="op">=</span>[<span class="st">"score"</span>, <span class="st">"parameters"</span>]))</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Finding out the best hyperparameters with highest Score</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>silhouette_scores_data.sort_values(by<span class="op">=</span><span class="st">'score'</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="48">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>score</th>
      <th>parameters</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.0, min_sample:5</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.0, min_sample:6</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.0, min_sample:7</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.0, min_sample:8</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.0, min_sample:9</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.5, min_sample:5</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.5, min_sample:6</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.5, min_sample:7</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.5, min_sample:8</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.489602</td>
      <td>eps:1.5, min_sample:9</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>sns.lineplot(x<span class="op">=</span><span class="st">"parameters"</span>, y<span class="op">=</span><span class="st">"score"</span>, data<span class="op">=</span>silhouette_scores_data[silhouette_scores_data[<span class="st">"score"</span>] <span class="op">&gt;</span> <span class="fl">0.45</span>].reset_index())  </span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'Hyper-parameter (Epsilon &amp; Min_Samples)'</span>, ylabel<span class="op">=</span><span class="st">'Silhouette Score'</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="st">'vertical'</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Pad margins so that markers don't get clipped by the axes</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>plt.margins(<span class="fl">0.2</span>)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Tweak spacing to prevent clipping of tick-labels</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(bottom<span class="op">=</span><span class="fl">0.15</span>)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-22-output-1.png" width="601" height="550"></p>
</div>
</div>
<p>A larger epsilon value produces broader clusters (encompassing more data points), and a smaller epsilon will build smaller clusters. Our silhouette plot does not show much variation in the scores based on different eps values and min_samples values. Therefore, we will choose the hyper-parameters eps = 1, and min_samples = 5, as we prefer smaller values such that we have only a small fraction of data points within the epsilon distance from each other.</p>
</section>
<section id="final-results-for-dbscan" class="level3">
<h3 class="anchored" data-anchor-id="final-results-for-dbscan">Final Results for DBSCAN</h3>
<div class="cell" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="dv">1</span>, min_samples<span class="op">=</span><span class="dv">5</span>) <span class="co"># best hyper-parameter values</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>model.fit(X)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.fit_predict(X)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>labels_DB <span class="op">=</span> model.labels_</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'DBSCAN_final_labels'</span>] <span class="op">=</span> labels_DB</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"unemployment_value"</span>, y<span class="op">=</span><span class="st">"fed_funds_value"</span>, hue<span class="op">=</span><span class="st">"recession"</span>, data<span class="op">=</span>df, ax<span class="op">=</span>ax[<span class="dv">0</span>]).<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Unemployment and Fed Funds Rates by Recession (Y)'</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"unemployment_value"</span>, y<span class="op">=</span><span class="st">"fed_funds_value"</span>, hue<span class="op">=</span><span class="st">"DBSCAN_final_labels"</span>, data<span class="op">=</span>df[df[<span class="st">'DBSCAN_final_labels'</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span> ], ax<span class="op">=</span>ax[<span class="dv">1</span>]).<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Final DBSCAN Clustering Plot'</span>) <span class="co"># removing label = -1 because it corresponds to noise</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>[Text(0.5, 1.0, 'Final DBSCAN Clustering Plot')]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-23-output-2.png" width="804" height="455"></p>
</div>
</div>
<div class="cell" data-execution_count="23">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of clusters in labels, ignoring noise if present.</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.metrics <span class="im">as</span> metrics</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>n_clusters_ <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(labels_DB)) <span class="op">-</span> (<span class="dv">1</span> <span class="cf">if</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">in</span> labels_DB <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>n_noise_ <span class="op">=</span> <span class="bu">list</span>(labels_DB).count(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>labels_true <span class="op">=</span> y</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated number of clusters: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> n_clusters_)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated number of noise points: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> n_noise_)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Homogeneity: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.homogeneity_score(labels_true, labels_DB))</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Completeness: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.completeness_score(labels_true, labels_DB))</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"V-measure: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.v_measure_score(labels_true, labels_DB))</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Adjusted Rand Index: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.adjusted_rand_score(labels_true, labels_DB))</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Adjusted Mutual Information: </span><span class="sc">%0.3f</span><span class="st">"</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    <span class="op">%</span> metrics.adjusted_mutual_info_score(labels_true, labels_DB)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Silhouette Coefficient: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> metrics.silhouette_score(X, labels_DB))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated number of clusters: 1
Estimated number of noise points: 1
Homogeneity: 0.051
Completeness: 0.389
V-measure: 0.090
Adjusted Rand Index: 0.108
Adjusted Mutual Information: 0.078
Silhouette Coefficient: 0.490</code></pre>
</div>
</div>
</section>
</section>
<section id="agglomerative-clustering-hierarchical-clustering" class="level2">
<h2 class="anchored" data-anchor-id="agglomerative-clustering-hierarchical-clustering">Agglomerative Clustering (Hierarchical clustering)</h2>
<div class="cell" data-execution_count="24">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform Agglomerative Clustering</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler </span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> dendrogram, linkage</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> AgglomerativeClustering</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.metrics</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.cluster</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_cluster</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'recession'</span>]</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AgglomerativeClustering(n_clusters<span class="op">=</span><span class="dv">3</span>, affinity<span class="op">=</span><span class="st">'euclidean'</span>,linkage<span class="op">=</span><span class="st">'ward'</span>).fit(X)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> model.labels_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="plot-clusters" class="level3">
<h3 class="anchored" data-anchor-id="plot-clusters">Plot Clusters</h3>
<div class="cell" data-execution_count="25">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> linkage(X, method<span class="op">=</span><span class="st">'ward'</span>) <span class="co"># linkage computed using euclidean distance  </span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>dend <span class="op">=</span> dendrogram(Z)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">30000</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'30000'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>&lt;matplotlib.lines.Line2D at 0x7fc8789a10c0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-26-output-2.png" width="595" height="413"></p>
</div>
</div>
<p>From the above dendogram, we set a threshold at value 30,000, and this cuts through the dendogram three times, giving us three clusters.</p>
</section>
<section id="hyper-parameter-tuning-2" class="level3">
<h3 class="anchored" data-anchor-id="hyper-parameter-tuning-2">Hyper-parameter Tuning</h3>
<div class="cell" data-execution_count="26">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> maximize_silhouette(X,algo<span class="op">=</span><span class="st">"birch"</span>,nmax<span class="op">=</span><span class="dv">20</span>,i_plot<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PARAM</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    i_print<span class="op">=</span><span class="va">False</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#FORCE CONTIGUOUS</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>np.ascontiguousarray(X) </span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># LOOP OVER HYPER-PARAM</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>[]<span class="op">;</span> sil_scores<span class="op">=</span>[]</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>    sil_max<span class="op">=-</span><span class="dv">10</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> param <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>,nmax<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(algo<span class="op">==</span><span class="st">"ag"</span>):</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> sklearn.cluster.AgglomerativeClustering(n_clusters<span class="op">=</span>param, affinity<span class="op">=</span><span class="st">"cosine"</span>, linkage<span class="op">=</span><span class="st">'single'</span>).fit(X)</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>            labels<span class="op">=</span>model.labels_</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>            sil_scores.append(sklearn.metrics.silhouette_score(X,labels))</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>            params.append(param)</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span>:</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span> </span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(i_print): <span class="bu">print</span>(param,sil_scores[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(sil_scores[<span class="op">-</span><span class="dv">1</span>]<span class="op">&gt;</span>sil_max):</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>             opt_param<span class="op">=</span>param</span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>             sil_max<span class="op">=</span>sil_scores[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>             opt_labels<span class="op">=</span>labels</span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"OPTIMAL PARAMETER ="</span>,opt_param)</span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(i_plot):</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>        ax.plot(params, sil_scores, <span class="st">"-o"</span>)  </span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>        ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'N_Clusters'</span>, ylabel<span class="op">=</span><span class="st">'Silhouette Score'</span>)</span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> opt_labels</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="27">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot(X,color_vector):</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    fig, [ax1, ax2] <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    sns.scatterplot(x<span class="op">=</span><span class="st">"unemployment_value"</span>, y<span class="op">=</span><span class="st">"fed_funds_value"</span>, hue<span class="op">=</span><span class="st">"recession"</span>, data<span class="op">=</span>df, ax<span class="op">=</span>ax1).<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Unemployment Rate and Federal Funds Rate by Recession'</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>    ax1.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'unemployment_value'</span>, ylabel<span class="op">=</span><span class="st">'fed_funds_value'</span>,</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">'Unemployment Rate and Fed Funds Rate by Recession (Y)'</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    ax1.grid()</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    scatter2 <span class="op">=</span> ax2.scatter(X[<span class="st">'unemployment_value'</span>], X[<span class="st">'fed_funds_value'</span>],c<span class="op">=</span>color_vector, alpha<span class="op">=</span><span class="fl">0.5</span>) </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    ax2.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">'unemployment_value'</span>, ylabel<span class="op">=</span><span class="st">'fed_funds_value'</span>,</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">'Agglomerative Clustering Plot'</span>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    legend2 <span class="op">=</span> ax2.legend(<span class="op">*</span>scatter2.legend_elements(),</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>                    loc<span class="op">=</span><span class="st">"lower right"</span>, title<span class="op">=</span><span class="st">"Clusters"</span>)</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>    ax2.add_artist(legend2)</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>    ax2.grid()</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="28">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>opt_labels<span class="op">=</span>maximize_silhouette(X,algo<span class="op">=</span><span class="st">"ag"</span>,nmax<span class="op">=</span><span class="dv">7</span>, i_plot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>plot(X,opt_labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>OPTIMAL PARAMETER = 5</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-29-output-2.png" width="601" height="435"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="dc_py_files/figure-html/cell-29-output-3.png" width="805" height="455"></p>
</div>
</div>
<p>Single-linkage uses the minimum of the distances between all observations of the two sets. For the above model, we also chose the affinity hyper-parameter, a metric used to compute the linkages, as cosine and found the the best number of clusters is five, as shown above in the first plot.</p>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>We performed clustering using three different methods, namely K-means, DBSCAN, and Agglomerative Clustering. The final result of the K-means model was based on the outputs of both the silhouette method and the elbow method, in adddition to an analysis of the silhouette plots for various values of k. The elbow method conveyes that k = 3 was the best parameter, but the silhouette method then yielded a value for k = 2 to be optimal. However, when we dove deeper into this, the silhouette score plots showed us that the ideal k was k = 3, as the silhouette plots were relatively even, in addition to not having a significantly different silhouette score compared to when k = 2.</p>
<p>The DBSCAN model performed the worst of the 3 clustering models. The initial parameter values yielded a silhouette score of -0.109, which signified that the data points are not well clustered to their own cluster, in comparison to other clusters. While the model yielded the same number of clusters as the K-means clustering model, which was 3. Furthermore, after hyperparameter tuning and testing for various values for eps and min_samples, we were not able to find meaningful differences in silhouette scores, thus proving that the model was not strong to cluster our data points.</p>
<p>Lastly, Agglomerative/Hierarchical clustering did a better job of clustering the feature data (X) than DBSCAN, but was still not as effective as K-means. By hyper-parameter turning in the Hierarchical clustering, we found our optimal paramter to be 5, yielding a silhouette score of ~0.15.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>To wrap up the clutering methods, we found that the K-means model clustered the feature data (X) the best of the 3 methods. The DBSCAN clustering performed the worst, and was not able to cluster data well, and the Hierarchical clustering model performed the second best. The main takeaway from this set of models was that although these clustering models are simple and easy to execute, they can be highly powerful to generate accurate insights from data, particularly if the right model is accurately chosen. The number of data points is crucial to these models, as a high number of data points will make the model better cluster the overall data. Additionally, more numeric features would also helpef the model, and would have to led to not only more clusters being formed, but clusters of various sizes and densities which would yield even more insightful results and takeaways.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p>Bock, Tim. “What Is a Dendrogram?” Displayr, September 13, 2022. https://www.displayr.com/what-is-dendrogram/.</p>
<p>Hashmi, Farukh. “How to Create Clusters Using DBSCAN in Python.” Thinking Neuron, November 27, 2021. https://thinkingneuron.com/how-to-create-clusters-using-dbscan-in-python/.</p>
<p>“Demo of DBSCAN Clustering Algorithm.” scikit. Accessed November 12, 2022. https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>