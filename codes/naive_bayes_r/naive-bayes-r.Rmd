---
title: "Naive Bayes in R"
author: "Raunak Advani"
date: "2022-12-07"
output: html_document
---

# Naive Bayes in R with Record Data

```{r}
library(rpart) # import relevant packages
library(RColorBrewer)
library(tidyverse)
library(wordcloud)
library(slam)
library(stringr)
library(textmineR)
library(caret)
library(pheatmap)
library(e1071)
```


```{r}
setwd("/Users/raunakadvani/anly-501-project-raunakadvani2410/codes/data-exploring")
df <- read.csv("../../data/clean-data/Fredapi_clean.csv")
library(lubridate)

str(df)
#month = format(ymd(df$date , "%Y-%m-%d"))

#df$date <- as.Date(paste(df$date,"-01",sep=""))  # Convert to date
df$month <- month(df$date)
df$month <- as.factor(df$month) # convert to factor
df$recession <- as.factor(df$recession)
df
```

```{r}
df <- subset(df, select = -c(date, X)) # drop redundant columns
df
```

## Create training and testing sets

```{r}
#Splitting into test and train
DataSize=nrow(df) 
TrainingSet_Size<-floor(DataSize*(3/4)) ## Size for training set
TestSet_Size <- DataSize - TrainingSet_Size ## Size for testing set

set.seed(2190)

## This is the sample of row numbers
MyTrainSample <- sample(nrow(df),
                         TrainingSet_Size,replace=FALSE)


MyTrainingSET <- df[MyTrainSample,]
table(MyTrainingSET$month)
```

```{r}
table(MyTrainingSET$recession)
```
```{r}
MyTestSET <- df[-MyTrainSample,]
table(MyTestSET$month)
```
```{r}
table(MyTestSET$recession)
```

```{r}
TestKnownLabels <- MyTestSET$recession
MyTestSET <- MyTestSET[ , -which(names(MyTestSET) %in% c("recession"))]
head(MyTestSET)
```
```{r}
TrainKnownLabels <- MyTrainingSET$recession
MyTrainingSET2 <- MyTrainingSET[ , -which(names(MyTrainingSET) %in% c("recession"))]
head(MyTrainingSET2)
```
```{r}
str(MyTrainingSET2)

```


```{r}
NB<-naiveBayes(MyTrainingSET, 
                        TrainKnownLabels, 
                        laplace = 1)

summary(NB)
```


```{r}
NB_Pred <- predict(NB, MyTestSET)
NB_Pred[1:10]
```

```{r}
data1 = table(NB_Pred,TestKnownLabels)
pheatmap(data1,display_numbers = T,color = colorRampPalette(c('white','red'))(100),cluster_rows = F, cluster_cols = F)
```

```{r}
confusionMatrix(NB_Pred,as.factor(TestKnownLabels))
```

```{r}
NB<-naiveBayes(MyTrainingSET, 
                        TrainKnownLabels, 
                        laplace = 1)

summary(NB)
```

```{r}
NB_Pred <- predict(NB, MyTestSET)
NB_Pred[1:10]
```

```{r}
data1 = table(NB_Pred,TestKnownLabels)
pheatmap(data1,display_numbers = T,color = colorRampPalette(c('white','red'))(100),cluster_rows = F, cluster_cols = F)
```

```{r}
confusionMatrix(NB_Pred,as.factor(TestKnownLabels))

```
```{r}
library(naivebayes)
```

```{r}
model <- naive_bayes(MyTrainingSET$recession ~ ., data = MyTrainingSET,laplace = 1)
model
```
```{r}
plot(model)
```
```{r}
NB_Pred2 <- predict(model, MyTestSET)
NB_Pred2[1:10]
```

```{r}
data2 = table(NB_Pred2,TestKnownLabels) ## make a confusion matrix

pheatmap(data2,display_numbers = T,color = colorRampPalette(c('white','red'))(100),cluster_rows = F, cluster_cols = F)
```
Classification Report

```{r}
confusionMatrix(NB_Pred2,as.factor(TestKnownLabels))
```

Overall, the results for my Naive Bayes classifier was quite impressive. The classifier had an accuracy core of 85.29%, which exceeded my expectations by a mile, and in addition, it also had a confidence interval of 68.89% - 95.05%, which was also quite solid. The model was able to predict a recessionary period quite well with the input training data. Another aspect that I would've liked to explore was weekends vs weekdays as predictions for interest rates. However, this was impossible for me to do as most economic data is released on a quarterly basis, limiting the amount of data that I have access to.